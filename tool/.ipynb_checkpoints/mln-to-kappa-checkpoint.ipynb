{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a8c3091-b495-44d5-bbde-6120fd5bc9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'parser' from '/Users/ivanprigarin/Library/Mobile Documents/com~apple~CloudDocs/cloud-files/1_study/cluster/code/mln-project/tool/parser.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-run this cell whenever parser.py is changed\n",
    "import importlib\n",
    "importlib.reload(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc7ab34c-2e2d-4f25-9fff-f0cc08443ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parser\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "530589bb-f798-4484-961e-5a4ecd90caf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing network configuration file network.txt\n",
      "{'actors': (['3', '1', '2'], 3),\n",
      " 'edges': ({'dir': [False, False, False, False, False],\n",
      "            'from_actor': ['1', '1', '2', '1', '1'],\n",
      "            'from_layer': ['2', '2', '2', '1', '1'],\n",
      "            'to_actor': ['2', '3', '3', '2', '3'],\n",
      "            'to_layer': ['2', '2', '2', '1', '1']},\n",
      "           [[('1', '2'),\n",
      "             ('2', '1'),\n",
      "             ('1', '3'),\n",
      "             ('3', '1'),\n",
      "             ('2', '3'),\n",
      "             ('3', '2')],\n",
      "            [('1', '2'), ('2', '1'), ('1', '3'), ('3', '1')]]),\n",
      " 'layers': (['2', '1'], 2)}\n"
     ]
    }
   ],
   "source": [
    "mln_data = parser.parse_mln('network.txt')\n",
    "pprint(mln_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cbae9f6-02f2-48d1-9a6c-16cd6e6fa4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MLN language file toy-example.mln\n",
      "{'initial conditions': ['1 = AI', '2 = US', '3 = US'],\n",
      " 'parameters': ['delta = 1', 'mu = 1', 'betaA = 1', 'betaU = 3', 'lamb = 1'],\n",
      " 'rules': ['AS -> US @ delta',\n",
      "           'AI -> AS @ mu',\n",
      "           'AS =1 AI -> AI =1 AI @ betaA',\n",
      "           'US =1 AI -> AI =1 AI @ betaU',\n",
      "           'US =2 AI -> AS =2 AI @ lamb',\n",
      "           'US =2 AS -> AS =2 AS @ lamb'],\n",
      " 'simOptions': ['n = 1000', 't = 30'],\n",
      " 'states': ['AS', 'AI', 'US'],\n",
      " 'views': ['AI', 'AS', 'US']}\n"
     ]
    }
   ],
   "source": [
    "language = parser.parse_language_file('toy-example.mln')\n",
    "pprint(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "95cd62bf-c6e6-407f-ab34-b0c9c8c9ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_signatures(mln_data, language):\n",
    "    signatures = ['/* Signatures */']\n",
    "    \n",
    "    states = []\n",
    "    for state in language['states']:\n",
    "        states.append(state)\n",
    "    states = '{' + ', '.join(states) + '}'\n",
    "\n",
    "    for i, actor in enumerate(mln_data['actors'][0]):\n",
    "        sites = []\n",
    "        for j, layer in enumerate(mln_data['edges'][1]):\n",
    "            for edge in layer:\n",
    "                if edge[0] == str(i+1):\n",
    "                    sites.append(f'l{j+1}v{edge[1]}')\n",
    "        sites = ', '.join(sites)\n",
    "                                 \n",
    "        kappa_signature = f'%agent: V{i+1}(state{states}, {sites})'\n",
    "        signatures.append(kappa_signature)\n",
    "        \n",
    "        \n",
    "    signatures = '\\n'.join(signatures)\n",
    "    \n",
    "    return signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1cd4aa59-11bf-46fb-9b00-fcba12b95e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Signatures */\n",
      "%agent: V1(state{AS, AI, US}, l1v2, l1v3, l2v2, l2v3)\n",
      "%agent: V2(state{AS, AI, US}, l1v1, l2v1, l2v3)\n",
      "%agent: V3(state{AS, AI, US}, l1v1, l2v1, l2v2)\n"
     ]
    }
   ],
   "source": [
    "print(parse_signatures(mln_data, language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78567761-4f7d-4f22-9496-31b8432a0161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_variables(language):\n",
    "    variables = ['/* Variables */']\n",
    "    \n",
    "    for param in language['parameters']:\n",
    "        var_name, var_value = param.split('=')\n",
    "        var = f\"%var: '{var_name.strip()}' {var_value.strip()}\"\n",
    "        variables.append(var)\n",
    "    variables = '\\n'.join(variables)\n",
    "    \n",
    "    return variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03a5c43d-932b-412b-a175-7a26149a7f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Variables */\n",
      "%var: 'delta' 1\n",
      "%var: 'mu' 1\n",
      "%var: 'betaA' 1\n",
      "%var: 'betaU' 3\n",
      "%var: 'lamb' 1\n"
     ]
    }
   ],
   "source": [
    "print(parse_variables(language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f313abcf-3b4c-4f7b-bd9e-bcc457ffad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_observables(mln_data, language):\n",
    "    observables = ['/* Observables */']\n",
    "    \n",
    "    for view in language['views']:\n",
    "        components = []\n",
    "        for i, actor in enumerate(mln_data['actors'][0]):\n",
    "            components.append(f'|V{i+1}(state{{{view}}})|')\n",
    "        obs = f\"%obs: '{view}' \" + ' + '.join(components)\n",
    "        observables.append(obs)\n",
    "    \n",
    "    observables = '\\n'.join(observables)\n",
    "    \n",
    "    return observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1ec28cf-ddb9-4d6b-a4af-a7791d183fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Observables */\n",
      "%obs: 'AI' |V1(state{AI})| + |V2(state{AI})| + |V3(state{AI})|\n",
      "%obs: 'AS' |V1(state{AS})| + |V2(state{AS})| + |V3(state{AS})|\n",
      "%obs: 'US' |V1(state{US})| + |V2(state{US})| + |V3(state{US})|\n"
     ]
    }
   ],
   "source": [
    "print(parse_observables(mln_data, language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "14f2863a-f6d1-4f53-bf40-3c4bee51b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_initial_conditions(mln_data, language):\n",
    "    n = ''\n",
    "    for line in language['simOptions']:\n",
    "        option, value = line.split('=')\n",
    "        if option.strip() == 'n':\n",
    "            n = value.strip()\n",
    "            break\n",
    "            \n",
    "    i_c = ['/* Initial conditions */',\n",
    "           f'%init: {n} (']\n",
    "    \n",
    "    initial_states = [x.split('=') for x in language['initial conditions']]\n",
    "\n",
    "    for i, actor in enumerate(mln_data['actors'][0]):\n",
    "        sites = []\n",
    "        site_labels = []\n",
    "        for j, layer in enumerate(mln_data['edges'][1]):\n",
    "            for edge in layer:\n",
    "                if edge[0] == str(i+1):\n",
    "                    # weird way to keep site labels consistent.\n",
    "                    # will need a rewrite\n",
    "                    if i+1 <= int(edge[1]):\n",
    "                        site_label = f'{j+1}{i+1}{edge[1]}'\n",
    "                    else:\n",
    "                        site_label = f'{j+1}{edge[1]}{i+1}'\n",
    "                        \n",
    "                    sites.append(f'l{j+1}v{edge[1]}[{site_label}]')\n",
    "        sites = ', '.join(sites)\n",
    "        \n",
    "        initial_state = ''\n",
    "        for state in initial_states:\n",
    "            if state[0].strip() == str(i+1):\n",
    "                initial_state = state[1].strip()\n",
    "                \n",
    "        condition = f'V{i+1}(state{{{initial_state}}}, {sites})'\n",
    "        \n",
    "        # add a comma unless it's the last entry\n",
    "        if i + 1 < int(mln_data['actors'][1]):\n",
    "            condition += ','\n",
    "        \n",
    "        i_c.append(condition)\n",
    "    \n",
    "    i_c.append(')')\n",
    "        \n",
    "    i_c = '\\n'.join(i_c)\n",
    "    \n",
    "    return i_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b17a1b54-1df4-494c-ab98-2423fc3bfdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Initial conditions */\n",
      "%init: 1000 (\n",
      "V1(state{AI}, l1v2[112], l1v3[113], l2v2[212], l2v3[213]),\n",
      "V2(state{US}, l1v1[112], l2v1[212], l2v3[223]),\n",
      "V3(state{US}, l1v1[113], l2v1[213], l2v2[223])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(parse_initial_conditions(mln_data, language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6f7a5425-dfc1-406c-a469-ca90b233858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rules(mln_data, language):\n",
    "    kappa_rules = ['/* Rules */']\n",
    "    \n",
    "    rules = [x.split('@') for x in language['rules']]\n",
    "    rules_organised = []\n",
    "    for ruleset in rules:\n",
    "        rules_organised.append({'rule': ruleset[0].strip(), 'rate': ruleset[1].strip()})\n",
    "\n",
    "    for ruleset in rules_organised:\n",
    "        if '=' not in ruleset['rule']:\n",
    "            # parse rules not dependant on layers\n",
    "            rule_states = [state.strip() for state in ruleset['rule'].split('->')]\n",
    "            kappa_rules.append(f\"'{rule_states[0]} to {rule_states[1]}'\")\n",
    "            for i, actor in enumerate(mln_data['actors'][0]):\n",
    "                kappa_rule = f\"V{i+1}(state{{{rule_states[0]}}}) -> V{i+1}(state{{{rule_states[1]}}}) @ '{ruleset['rate']}'\"\n",
    "                kappa_rules.append(kappa_rule)\n",
    "        else:\n",
    "            # parse intra-layer rules\n",
    "            # requires rules in both directions\n",
    "            rule_sides = [state.strip() for state in ruleset['rule'].split('->')]\n",
    "            layer = rule_sides[0][rule_sides[0].index('=')+1].strip()\n",
    "\n",
    "            states = [[x[0].strip(), x[1].strip()] for x in [rule_side.split(f'={layer}') for rule_side in rule_sides]]\n",
    "            kappa_rules.append(f\"'{layer}: {states[0][0]}-{states[0][1]} to {states[1][0]}-{states[1][1]}'\")\n",
    "            for edge in mln_data['edges'][1][int(layer)-1]:\n",
    "                v1, v2 = edge[0], edge[1]\n",
    "                kappa_rules.append(f\"// V{v1} - V{v2}\")\n",
    "                site_label = f'{layer}{v1}{v2}'\n",
    "                kappa_rule = (f'V{v1}(state{{{states[0][0]}}}, l{layer}v{v2}[{site_label}]), V{v2}(state{{{states[0][1]}}}, l{layer}v{v1}[{site_label}]) -> '\n",
    "                    f'V{v1}(state{{{states[1][0]}}}, l{layer}v{v2}[{site_label}]), V{v2}(state{{{states[1][1]}}}, l{layer}v{v1}[{site_label}]) @ '\n",
    "                    f\"'{ruleset['rate']}'\")\n",
    "\n",
    "                kappa_rules.append(kappa_rule)\n",
    "\n",
    "        kappa_rules.append('')\n",
    "\n",
    "    kappa_rules = '\\n'.join(kappa_rules)\n",
    "\n",
    "    return kappa_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4ca1327c-56a6-4ece-980b-abbaa8747e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Rules */\n",
      "'AS to US'\n",
      "V1(state{AS}) -> V1(state{US}) @ 'delta'\n",
      "V2(state{AS}) -> V2(state{US}) @ 'delta'\n",
      "V3(state{AS}) -> V3(state{US}) @ 'delta'\n",
      "\n",
      "'AI to AS'\n",
      "V1(state{AI}) -> V1(state{AS}) @ 'mu'\n",
      "V2(state{AI}) -> V2(state{AS}) @ 'mu'\n",
      "V3(state{AI}) -> V3(state{AS}) @ 'mu'\n",
      "\n",
      "'1: AS-AI to AI-AI'\n",
      "// V1 - V2\n",
      "V1(state{AS}, l1v2[112]), V2(state{AI}, l1v1[112]) -> V1(state{AI}, l1v2[112]), V2(state{AI}, l1v1[112]) @ 'betaA'\n",
      "// V2 - V1\n",
      "V2(state{AS}, l1v1[121]), V1(state{AI}, l1v2[121]) -> V2(state{AI}, l1v1[121]), V1(state{AI}, l1v2[121]) @ 'betaA'\n",
      "// V1 - V3\n",
      "V1(state{AS}, l1v3[113]), V3(state{AI}, l1v1[113]) -> V1(state{AI}, l1v3[113]), V3(state{AI}, l1v1[113]) @ 'betaA'\n",
      "// V3 - V1\n",
      "V3(state{AS}, l1v1[131]), V1(state{AI}, l1v3[131]) -> V3(state{AI}, l1v1[131]), V1(state{AI}, l1v3[131]) @ 'betaA'\n",
      "\n",
      "'1: US-AI to AI-AI'\n",
      "// V1 - V2\n",
      "V1(state{US}, l1v2[112]), V2(state{AI}, l1v1[112]) -> V1(state{AI}, l1v2[112]), V2(state{AI}, l1v1[112]) @ 'betaU'\n",
      "// V2 - V1\n",
      "V2(state{US}, l1v1[121]), V1(state{AI}, l1v2[121]) -> V2(state{AI}, l1v1[121]), V1(state{AI}, l1v2[121]) @ 'betaU'\n",
      "// V1 - V3\n",
      "V1(state{US}, l1v3[113]), V3(state{AI}, l1v1[113]) -> V1(state{AI}, l1v3[113]), V3(state{AI}, l1v1[113]) @ 'betaU'\n",
      "// V3 - V1\n",
      "V3(state{US}, l1v1[131]), V1(state{AI}, l1v3[131]) -> V3(state{AI}, l1v1[131]), V1(state{AI}, l1v3[131]) @ 'betaU'\n",
      "\n",
      "'2: US-AI to AS-AI'\n",
      "// V1 - V2\n",
      "V1(state{US}, l2v2[212]), V2(state{AI}, l2v1[212]) -> V1(state{AS}, l2v2[212]), V2(state{AI}, l2v1[212]) @ 'lamb'\n",
      "// V2 - V1\n",
      "V2(state{US}, l2v1[221]), V1(state{AI}, l2v2[221]) -> V2(state{AS}, l2v1[221]), V1(state{AI}, l2v2[221]) @ 'lamb'\n",
      "// V1 - V3\n",
      "V1(state{US}, l2v3[213]), V3(state{AI}, l2v1[213]) -> V1(state{AS}, l2v3[213]), V3(state{AI}, l2v1[213]) @ 'lamb'\n",
      "// V3 - V1\n",
      "V3(state{US}, l2v1[231]), V1(state{AI}, l2v3[231]) -> V3(state{AS}, l2v1[231]), V1(state{AI}, l2v3[231]) @ 'lamb'\n",
      "// V2 - V3\n",
      "V2(state{US}, l2v3[223]), V3(state{AI}, l2v2[223]) -> V2(state{AS}, l2v3[223]), V3(state{AI}, l2v2[223]) @ 'lamb'\n",
      "// V3 - V2\n",
      "V3(state{US}, l2v2[232]), V2(state{AI}, l2v3[232]) -> V3(state{AS}, l2v2[232]), V2(state{AI}, l2v3[232]) @ 'lamb'\n",
      "\n",
      "'2: US-AS to AS-AS'\n",
      "// V1 - V2\n",
      "V1(state{US}, l2v2[212]), V2(state{AS}, l2v1[212]) -> V1(state{AS}, l2v2[212]), V2(state{AS}, l2v1[212]) @ 'lamb'\n",
      "// V2 - V1\n",
      "V2(state{US}, l2v1[221]), V1(state{AS}, l2v2[221]) -> V2(state{AS}, l2v1[221]), V1(state{AS}, l2v2[221]) @ 'lamb'\n",
      "// V1 - V3\n",
      "V1(state{US}, l2v3[213]), V3(state{AS}, l2v1[213]) -> V1(state{AS}, l2v3[213]), V3(state{AS}, l2v1[213]) @ 'lamb'\n",
      "// V3 - V1\n",
      "V3(state{US}, l2v1[231]), V1(state{AS}, l2v3[231]) -> V3(state{AS}, l2v1[231]), V1(state{AS}, l2v3[231]) @ 'lamb'\n",
      "// V2 - V3\n",
      "V2(state{US}, l2v3[223]), V3(state{AS}, l2v2[223]) -> V2(state{AS}, l2v3[223]), V3(state{AS}, l2v2[223]) @ 'lamb'\n",
      "// V3 - V2\n",
      "V3(state{US}, l2v2[232]), V2(state{AS}, l2v3[232]) -> V3(state{AS}, l2v2[232]), V2(state{AS}, l2v3[232]) @ 'lamb'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(parse_rules(mln_data, language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7d13885a-1299-4df7-9b5d-15b68b03f119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing network configuration file network.txt\n",
      "Parsing MLN language file toy-example.mln\n",
      "Successfully exported model into Kappa: out-kappa.txt\n"
     ]
    }
   ],
   "source": [
    "parser.parse_to_kappa('network.txt', 'toy-example.mln', 'out-kappa.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f472fe-c57f-46c1-9c17-b010b49ac9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddcffc8-d8c5-4fbc-91ef-90b8297d96b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2feb96-66c7-45c1-b9f1-99790f2912e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c436047-5a45-4020-b7c5-a3f1e38fb4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "810b134e-20a6-4293-9048-8d0548835c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing network configuration file network-four-nodes.txt\n",
      "Parsing MLN language file toy-example-four-nodes.mln\n"
     ]
    }
   ],
   "source": [
    "mln_data_4 = parser.parse_mln('network-four-nodes.txt')\n",
    "language_4 = parser.parse_language_file('toy-example-four-nodes.mln')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "895feb3c-f489-45cc-8887-929581c8aa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'actors': (['1', '2', '3', '4'], 4),\n",
      " 'edges': ({'dir': [False,\n",
      "                    False,\n",
      "                    False,\n",
      "                    False,\n",
      "                    False,\n",
      "                    False,\n",
      "                    False,\n",
      "                    False,\n",
      "                    False],\n",
      "            'from_actor': ['1', '1', '1', '1', '1', '1', '2', '2', '3'],\n",
      "            'from_layer': ['1', '1', '1', '2', '2', '2', '2', '2', '2'],\n",
      "            'to_actor': ['2', '3', '4', '2', '3', '4', '3', '4', '4'],\n",
      "            'to_layer': ['1', '1', '1', '2', '2', '2', '2', '2', '2']},\n",
      "           [[('1', '2'),\n",
      "             ('2', '1'),\n",
      "             ('1', '3'),\n",
      "             ('3', '1'),\n",
      "             ('1', '4'),\n",
      "             ('4', '1')],\n",
      "            [('1', '2'),\n",
      "             ('2', '1'),\n",
      "             ('1', '3'),\n",
      "             ('3', '1'),\n",
      "             ('1', '4'),\n",
      "             ('4', '1'),\n",
      "             ('2', '3'),\n",
      "             ('3', '2'),\n",
      "             ('2', '4'),\n",
      "             ('4', '2'),\n",
      "             ('3', '4'),\n",
      "             ('4', '3')]]),\n",
      " 'layers': (['1', '2'], 2)}\n"
     ]
    }
   ],
   "source": [
    "pprint(mln_data_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7490592f-f9f2-47e5-9911-3258763317e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'initial conditions': ['1 = AI', '2 = US', '3 = US', '4 = US'],\n",
      " 'parameters': ['delta = 1', 'mu = 1', 'betaA = 1', 'betaU = 3', 'lamb = 1'],\n",
      " 'rules': ['AS -> US @ delta',\n",
      "           'AI -> AS @ mu',\n",
      "           'AS =1 AI -> AI =1 AI @ betaA',\n",
      "           'US =1 AI -> AI =1 AI @ betaU',\n",
      "           'US =2 AI -> AS =2 AI @ lamb',\n",
      "           'US =2 AS -> AS =2 AS @ lamb'],\n",
      " 'simOptions': ['n = 1000', 't = 80'],\n",
      " 'states': ['AS', 'AI', 'US'],\n",
      " 'views': ['AI', 'AS', 'US']}\n"
     ]
    }
   ],
   "source": [
    "pprint(language_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b57b3b8-c3f2-46c2-a750-216383116a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Signatures */\n",
      "%agent: V1(state{AS, AI, US}, l1v2, l1v3, l1v4, l2v2, l2v3, l2v4)\n",
      "%agent: V2(state{AS, AI, US}, l1v1, l2v1, l2v3, l2v4)\n",
      "%agent: V3(state{AS, AI, US}, l1v1, l2v1, l2v2, l2v4)\n",
      "%agent: V4(state{AS, AI, US}, l1v1, l2v1, l2v2, l2v3)\n"
     ]
    }
   ],
   "source": [
    "print(parser.parse_signatures(mln_data_4, language_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b5e4b8-6ec0-4ab5-b459-4e995c1b7a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5456f410-9218-47b8-a8e0-e42d6fcecc64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f150f6ef-fa6d-4698-bbd2-a3801a429330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b88fc37-c9a6-41ef-ae74-e66e266999b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'actors': (['1', '2', '3'], 3),\n",
      " 'edges': ({'dir': [False, False, False, False, False],\n",
      "            'from_actor': ['1', '1', '1', '1', '2'],\n",
      "            'from_layer': ['1', '1', '2', '2', '2'],\n",
      "            'to_actor': ['2', '3', '2', '3', '3'],\n",
      "            'to_layer': ['1', '1', '2', '2', '2']},\n",
      "           [[('1', '2'), ('2', '1'), ('1', '3'), ('3', '1')],\n",
      "            [('1', '2'),\n",
      "             ('2', '1'),\n",
      "             ('1', '3'),\n",
      "             ('3', '1'),\n",
      "             ('2', '3'),\n",
      "             ('3', '2')]]),\n",
      " 'layers': (['1', '2'], 2)}\n"
     ]
    }
   ],
   "source": [
    "pprint(mln_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c91189a-6d49-4bd5-8e5f-44930e973ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'initial conditions': ['1 = AI', '2 = US', '3 = US'],\n",
      " 'parameters': ['delta = 1', 'mu = 1', 'betaA = 1', 'betaU = 3', 'lamb = 1'],\n",
      " 'rules': ['AS -> US @ delta',\n",
      "           'AI -> AS @ mu',\n",
      "           'AS =1 AI -> AI =1 AI @ betaA',\n",
      "           'US =1 AI -> AI =1 AI @ betaU',\n",
      "           'US =2 AI -> AS =2 AI @ lamb',\n",
      "           'US =2 AS -> AS =2 AS @ lamb'],\n",
      " 'simOptions': ['n = 1000', 't = 30'],\n",
      " 'states': ['AS', 'AI', 'US'],\n",
      " 'views': ['AI', 'AS', 'US']}\n"
     ]
    }
   ],
   "source": [
    "pprint(language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2de32ae-d375-4193-89ca-75476426962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_to_gillespy(network_filename, language_filename, out_filename):\n",
    "    mln_data = parser.parse_mln(network_filename)\n",
    "    language = parser.parse_language_file(language_filename)\n",
    "\n",
    "    tab = '\\t'\n",
    "\n",
    "    header_string = (\n",
    "        f'import numpy\\n'\n",
    "        f'import matplotlib.pyplot as plt\\n'\n",
    "        f'from gillespy2.core import (\\n'\n",
    "        f'{tab}Model,\\n'\n",
    "        f'{tab}Species,\\n'\n",
    "        f'{tab}Reaction,\\n'\n",
    "        f'{tab}Parameter)\\n\\n'\n",
    "        f'class Mln_dynamics(Model):\\n'\n",
    "        f'{tab}def __init__(self,parameter_values=None):\\n'\n",
    "        f'{tab * 2}Model.__init__(self, name=\"MLN\")\\n\\n'\n",
    "    )\n",
    "    \n",
    "    params = gillespie_parse_parameters(language)\n",
    "    species = gillespie_parse_species(mln_data, language)\n",
    "    reactions = gillespie_parse_reactions(mln_data, language)\n",
    "    timespan = gillespie_parse_timespan(mln_data, language)\n",
    "    \n",
    "    result = (\n",
    "        header_string +\n",
    "        params + '\\n' +\n",
    "        species + '\\n' +\n",
    "        reactions + '\\n' +\n",
    "        timespan)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def gillespie_parse_parameters(language):\n",
    "    tab = '\\t'\n",
    "    params = []\n",
    "    param_names = []\n",
    "    \n",
    "    for param in language['parameters']:\n",
    "        name, value = param.split('=')\n",
    "        param_names.append(name.strip())\n",
    "        params.append(f\"{tab}{tab}{name.strip()} = Parameter(name='{name}', expression={value})\")\n",
    "    \n",
    "    params.append(f\"{tab}{tab}self.add_parameter([{', '.join(param_names)}])\\n\")\n",
    "    params = '\\n'.join(params)\n",
    "    \n",
    "    return params\n",
    "\n",
    "\n",
    "def gillespie_parse_species(mln_data, language):\n",
    "    tab = '\\t'\n",
    "    species = []\n",
    "    species_names = []\n",
    "    \n",
    "    for state in language['states']:\n",
    "        for actor in mln_data['actors'][0]:\n",
    "            species_names.append(f\"{state}{actor}\")\n",
    "            init_value = 0\n",
    "            for init_conditions in language['initial conditions']:\n",
    "                name, value = init_conditions.split('=')\n",
    "                if actor == name.strip() and state == value.strip():\n",
    "                    init_value = 1\n",
    "                    break\n",
    "            species.append(f\"{tab}{tab}{state}{actor} = Species(name='{state}{actor}', initial_value={init_value})\")\n",
    "    \n",
    "    species.append(f\"{tab}{tab}self.add_species([{', '.join(species_names)}])\\n\")\n",
    "    species = '\\n'.join(species)\n",
    "    \n",
    "    return species\n",
    "\n",
    "\n",
    "def gillespie_parse_reactions(mln_data, language):\n",
    "    tab = '\\t'\n",
    "    reactions = []\n",
    "    reaction_names = []\n",
    "    counter = 0\n",
    "    \n",
    "    for rule in language['rules']:\n",
    "        nodes, rate = rule.split('@')\n",
    "        rate = rate.strip()\n",
    "        \n",
    "        if '=' not in nodes:\n",
    "            # a simple state-to-state rule for a single node\n",
    "            left_node, right_node = nodes.split('->')\n",
    "            left_node = left_node.strip()\n",
    "            right_node = right_node.strip()\n",
    "            \n",
    "            for i in range(1, mln_data['actors'][1] + 1):\n",
    "                name = f\"{counter}_{left_node}{i}_to_{right_node}{i}\"\n",
    "                reaction = (\n",
    "                    f\"{tab * 2}{name} = Reaction(\\n\"\n",
    "                    f\"{tab * 4}name = '{name}',\\n\"\n",
    "                    f\"{tab * 4}rate = {rate},\\n\"\n",
    "                    f\"{tab * 4}reactants = {{{left_node}{i}: 1}},\\n\"\n",
    "                    f\"{tab * 4}products = {{{right_node}{i}: 1}}\\n\"\n",
    "                    f\"{tab * 3})\\n\"\n",
    "                )\n",
    "                \n",
    "                reactions.append(reaction)\n",
    "                reaction_names.append(name)\n",
    "                counter += 1\n",
    "        else:\n",
    "            # two-node rule\n",
    "            left_side, right_side = nodes.split('->')\n",
    "            layer_index = int(left_side[left_side.index('=')+1].strip())\n",
    "            \n",
    "            left_reactant_1, left_reactant_2 = left_side.split(f\"={layer_index}\")\n",
    "            right_reactant_1, right_reactant_2 = right_side.split(f\"={layer_index}\")\n",
    "            \n",
    "            left_reactant_1 = left_reactant_1.strip()\n",
    "            left_reactant_2 = left_reactant_2.strip()\n",
    "            right_reactant_1 = right_reactant_1.strip()\n",
    "            right_reactant_2 = right_reactant_2.strip()\n",
    "            \n",
    "            for edge in mln_data['edges'][1][layer_index-1]:\n",
    "                # note that this list already takes into account directionality of edges\n",
    "                name = f\"{counter}_{left_reactant_1}{edge[0]}_{left_reactant_2}{edge[1]}_to_{right_reactant_1}{edge[0]}_{right_reactant_2}{edge[1]}\"\n",
    "                reaction = (\n",
    "                    f\"{tab * 2}{name} = Reaction(\\n\"\n",
    "                    f\"{tab * 4}name = '{name}',\\n\"\n",
    "                    f\"{tab * 4}rate = {rate},\\n\"\n",
    "                    f\"{tab * 4}reactants = {{{left_reactant_1}{edge[0]}: 1, {left_reactant_2}{edge[1]}: 1}},\\n\"\n",
    "                    f\"{tab * 4}products = {{{right_reactant_1}{edge[0]}: 1, {right_reactant_2}{edge[1]}: 1}}\\n\"\n",
    "                    f\"{tab * 3})\\n\"\n",
    "                )\n",
    "                \n",
    "                reactions.append(reaction)\n",
    "                reaction_names.append(name)\n",
    "                counter += 1\n",
    "                \n",
    "    \n",
    "    reactions.append(f\"{tab * 2}self.add_reaction([{', '.join(reaction_names)}])\\n\")\n",
    "    reactions = '\\n'.join(reactions)\n",
    "    \n",
    "    return reactions\n",
    "\n",
    "\n",
    "def gillespie_parse_timespan(mln_data, language):\n",
    "    tab = '\\t'\n",
    "    t_value = int(language['simOptions'][1].split('=')[1].strip())\n",
    "    \n",
    "    # note that below t_value is multiplied by 20 - I don't know why\n",
    "    timespan = f\"{tab * 2}self.timespan(numpy.linspace(0, {t_value}, {t_value * 20}))\\n\"\n",
    "    \n",
    "    return timespan\n",
    "\n",
    "\n",
    "def gillespie_parse_sim_options(mln_data, language):\n",
    "    tab = '\\t'\n",
    "    n_value = int(language['simOptions'][0].split('=')[1].strip())\n",
    "    trajectories = [[] for i in range(len(language['views']))]\n",
    "    trajectories_loop = []\n",
    "    \n",
    "    list_of_colors = ['b','g','r','c','m','y','k']\n",
    "    active_color = 0\n",
    "    for view, i in enumerate(language['views']):\n",
    "        appends = []\n",
    "        for actor in mln_data['actors'][0]:\n",
    "            appends.append(f\"trajectory['{view}{actor}'][i]\"\n",
    "        \n",
    "        appends = ' + '.join(appends)      \n",
    "        trajectories_loop.append(f\"{tab * 2}trajectories[{i}].append({appends})\")\n",
    "                           \n",
    "    trajectories_loop = '\\n'.join(trajectories_loop)\n",
    "                           \n",
    "    footer = (\n",
    "        f\"def run_sim(model):\\n\"\n",
    "        f\"{tab}results = model.run(number_of_trajectories={n_value})\\n\"\n",
    "        f\"{tab}trajectory = results.average_ensemble()\\n\"\n",
    "        f\"{tab}plt.figure()\\n\"\n",
    "        f\"{tab}trajectories = {trajectories}\\n\"\n",
    "        f\"{tab}for i in range(len(trajectory['{language['views'][0]}1'])):\\n\"\n",
    "        f\"{trajectories_loop}\\n\"\n",
    "    )\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e71ccbe-ee4b-4eb2-9069-35ac739fc7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing network configuration file network.txt\n",
      "Parsing MLN language file toy-example.mln\n",
      "import numpy\n",
      "import matplotlib.pyplot as plt\n",
      "from gillespy2.core import (\n",
      "\tModel,\n",
      "\tSpecies,\n",
      "\tReaction,\n",
      "\tParameter)\n",
      "\n",
      "class Mln_dynamics(Model):\n",
      "\tdef __init__(self,parameter_values=None):\n",
      "\t\tModel.__init__(self, name=\"MLN\")\n",
      "\n",
      "\t\tdelta = Parameter(name='delta ', expression= 1)\n",
      "\t\tmu = Parameter(name='mu ', expression= 1)\n",
      "\t\tbetaA = Parameter(name='betaA ', expression= 1)\n",
      "\t\tbetaU = Parameter(name='betaU ', expression= 3)\n",
      "\t\tlamb = Parameter(name='lamb ', expression= 1)\n",
      "\t\tself.add_parameter([delta, mu, betaA, betaU, lamb])\n",
      "\n",
      "\t\tAS1 = Species(name='AS1', initial_value=0)\n",
      "\t\tAS2 = Species(name='AS2', initial_value=0)\n",
      "\t\tAS3 = Species(name='AS3', initial_value=0)\n",
      "\t\tAI1 = Species(name='AI1', initial_value=1)\n",
      "\t\tAI2 = Species(name='AI2', initial_value=0)\n",
      "\t\tAI3 = Species(name='AI3', initial_value=0)\n",
      "\t\tUS1 = Species(name='US1', initial_value=0)\n",
      "\t\tUS2 = Species(name='US2', initial_value=1)\n",
      "\t\tUS3 = Species(name='US3', initial_value=1)\n",
      "\t\tself.add_species([AS1, AS2, AS3, AI1, AI2, AI3, US1, US2, US3])\n",
      "\n",
      "\t\t0_AS1_to_US1 = Reaction(\n",
      "\t\t\t\tname = '0_AS1_to_US1',\n",
      "\t\t\t\trate = delta,\n",
      "\t\t\t\treactants = {AS1: 1},\n",
      "\t\t\t\tproducts = {US1: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t1_AS2_to_US2 = Reaction(\n",
      "\t\t\t\tname = '1_AS2_to_US2',\n",
      "\t\t\t\trate = delta,\n",
      "\t\t\t\treactants = {AS2: 1},\n",
      "\t\t\t\tproducts = {US2: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t2_AS3_to_US3 = Reaction(\n",
      "\t\t\t\tname = '2_AS3_to_US3',\n",
      "\t\t\t\trate = delta,\n",
      "\t\t\t\treactants = {AS3: 1},\n",
      "\t\t\t\tproducts = {US3: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t3_AI1_to_AS1 = Reaction(\n",
      "\t\t\t\tname = '3_AI1_to_AS1',\n",
      "\t\t\t\trate = mu,\n",
      "\t\t\t\treactants = {AI1: 1},\n",
      "\t\t\t\tproducts = {AS1: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t4_AI2_to_AS2 = Reaction(\n",
      "\t\t\t\tname = '4_AI2_to_AS2',\n",
      "\t\t\t\trate = mu,\n",
      "\t\t\t\treactants = {AI2: 1},\n",
      "\t\t\t\tproducts = {AS2: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t5_AI3_to_AS3 = Reaction(\n",
      "\t\t\t\tname = '5_AI3_to_AS3',\n",
      "\t\t\t\trate = mu,\n",
      "\t\t\t\treactants = {AI3: 1},\n",
      "\t\t\t\tproducts = {AS3: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t6_AS1_AI2_to_AI1_AI2 = Reaction(\n",
      "\t\t\t\tname = '6_AS1_AI2_to_AI1_AI2',\n",
      "\t\t\t\trate = betaA,\n",
      "\t\t\t\treactants = {AS1: 1, AI2: 1},\n",
      "\t\t\t\tproducts = {AI1: 1, AI2: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t7_AS2_AI1_to_AI2_AI1 = Reaction(\n",
      "\t\t\t\tname = '7_AS2_AI1_to_AI2_AI1',\n",
      "\t\t\t\trate = betaA,\n",
      "\t\t\t\treactants = {AS2: 1, AI1: 1},\n",
      "\t\t\t\tproducts = {AI2: 1, AI1: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t8_AS1_AI3_to_AI1_AI3 = Reaction(\n",
      "\t\t\t\tname = '8_AS1_AI3_to_AI1_AI3',\n",
      "\t\t\t\trate = betaA,\n",
      "\t\t\t\treactants = {AS1: 1, AI3: 1},\n",
      "\t\t\t\tproducts = {AI1: 1, AI3: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t9_AS3_AI1_to_AI3_AI1 = Reaction(\n",
      "\t\t\t\tname = '9_AS3_AI1_to_AI3_AI1',\n",
      "\t\t\t\trate = betaA,\n",
      "\t\t\t\treactants = {AS3: 1, AI1: 1},\n",
      "\t\t\t\tproducts = {AI3: 1, AI1: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t10_AS2_AI3_to_AI2_AI3 = Reaction(\n",
      "\t\t\t\tname = '10_AS2_AI3_to_AI2_AI3',\n",
      "\t\t\t\trate = betaA,\n",
      "\t\t\t\treactants = {AS2: 1, AI3: 1},\n",
      "\t\t\t\tproducts = {AI2: 1, AI3: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t11_AS3_AI2_to_AI3_AI2 = Reaction(\n",
      "\t\t\t\tname = '11_AS3_AI2_to_AI3_AI2',\n",
      "\t\t\t\trate = betaA,\n",
      "\t\t\t\treactants = {AS3: 1, AI2: 1},\n",
      "\t\t\t\tproducts = {AI3: 1, AI2: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t12_US1_AI2_to_AI1_AI2 = Reaction(\n",
      "\t\t\t\tname = '12_US1_AI2_to_AI1_AI2',\n",
      "\t\t\t\trate = betaU,\n",
      "\t\t\t\treactants = {US1: 1, AI2: 1},\n",
      "\t\t\t\tproducts = {AI1: 1, AI2: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t13_US2_AI1_to_AI2_AI1 = Reaction(\n",
      "\t\t\t\tname = '13_US2_AI1_to_AI2_AI1',\n",
      "\t\t\t\trate = betaU,\n",
      "\t\t\t\treactants = {US2: 1, AI1: 1},\n",
      "\t\t\t\tproducts = {AI2: 1, AI1: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t14_US1_AI3_to_AI1_AI3 = Reaction(\n",
      "\t\t\t\tname = '14_US1_AI3_to_AI1_AI3',\n",
      "\t\t\t\trate = betaU,\n",
      "\t\t\t\treactants = {US1: 1, AI3: 1},\n",
      "\t\t\t\tproducts = {AI1: 1, AI3: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t15_US3_AI1_to_AI3_AI1 = Reaction(\n",
      "\t\t\t\tname = '15_US3_AI1_to_AI3_AI1',\n",
      "\t\t\t\trate = betaU,\n",
      "\t\t\t\treactants = {US3: 1, AI1: 1},\n",
      "\t\t\t\tproducts = {AI3: 1, AI1: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t16_US2_AI3_to_AI2_AI3 = Reaction(\n",
      "\t\t\t\tname = '16_US2_AI3_to_AI2_AI3',\n",
      "\t\t\t\trate = betaU,\n",
      "\t\t\t\treactants = {US2: 1, AI3: 1},\n",
      "\t\t\t\tproducts = {AI2: 1, AI3: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t17_US3_AI2_to_AI3_AI2 = Reaction(\n",
      "\t\t\t\tname = '17_US3_AI2_to_AI3_AI2',\n",
      "\t\t\t\trate = betaU,\n",
      "\t\t\t\treactants = {US3: 1, AI2: 1},\n",
      "\t\t\t\tproducts = {AI3: 1, AI2: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t18_US1_AI2_to_AS1_AI2 = Reaction(\n",
      "\t\t\t\tname = '18_US1_AI2_to_AS1_AI2',\n",
      "\t\t\t\trate = lamb,\n",
      "\t\t\t\treactants = {US1: 1, AI2: 1},\n",
      "\t\t\t\tproducts = {AS1: 1, AI2: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t19_US2_AI1_to_AS2_AI1 = Reaction(\n",
      "\t\t\t\tname = '19_US2_AI1_to_AS2_AI1',\n",
      "\t\t\t\trate = lamb,\n",
      "\t\t\t\treactants = {US2: 1, AI1: 1},\n",
      "\t\t\t\tproducts = {AS2: 1, AI1: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t20_US1_AI3_to_AS1_AI3 = Reaction(\n",
      "\t\t\t\tname = '20_US1_AI3_to_AS1_AI3',\n",
      "\t\t\t\trate = lamb,\n",
      "\t\t\t\treactants = {US1: 1, AI3: 1},\n",
      "\t\t\t\tproducts = {AS1: 1, AI3: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t21_US3_AI1_to_AS3_AI1 = Reaction(\n",
      "\t\t\t\tname = '21_US3_AI1_to_AS3_AI1',\n",
      "\t\t\t\trate = lamb,\n",
      "\t\t\t\treactants = {US3: 1, AI1: 1},\n",
      "\t\t\t\tproducts = {AS3: 1, AI1: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t22_US1_AS2_to_AS1_AS2 = Reaction(\n",
      "\t\t\t\tname = '22_US1_AS2_to_AS1_AS2',\n",
      "\t\t\t\trate = lamb,\n",
      "\t\t\t\treactants = {US1: 1, AS2: 1},\n",
      "\t\t\t\tproducts = {AS1: 1, AS2: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t23_US2_AS1_to_AS2_AS1 = Reaction(\n",
      "\t\t\t\tname = '23_US2_AS1_to_AS2_AS1',\n",
      "\t\t\t\trate = lamb,\n",
      "\t\t\t\treactants = {US2: 1, AS1: 1},\n",
      "\t\t\t\tproducts = {AS2: 1, AS1: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t24_US1_AS3_to_AS1_AS3 = Reaction(\n",
      "\t\t\t\tname = '24_US1_AS3_to_AS1_AS3',\n",
      "\t\t\t\trate = lamb,\n",
      "\t\t\t\treactants = {US1: 1, AS3: 1},\n",
      "\t\t\t\tproducts = {AS1: 1, AS3: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\t25_US3_AS1_to_AS3_AS1 = Reaction(\n",
      "\t\t\t\tname = '25_US3_AS1_to_AS3_AS1',\n",
      "\t\t\t\trate = lamb,\n",
      "\t\t\t\treactants = {US3: 1, AS1: 1},\n",
      "\t\t\t\tproducts = {AS3: 1, AS1: 1}\n",
      "\t\t\t)\n",
      "\n",
      "\t\tself.add_reaction([0_AS1_to_US1, 1_AS2_to_US2, 2_AS3_to_US3, 3_AI1_to_AS1, 4_AI2_to_AS2, 5_AI3_to_AS3, 6_AS1_AI2_to_AI1_AI2, 7_AS2_AI1_to_AI2_AI1, 8_AS1_AI3_to_AI1_AI3, 9_AS3_AI1_to_AI3_AI1, 10_AS2_AI3_to_AI2_AI3, 11_AS3_AI2_to_AI3_AI2, 12_US1_AI2_to_AI1_AI2, 13_US2_AI1_to_AI2_AI1, 14_US1_AI3_to_AI1_AI3, 15_US3_AI1_to_AI3_AI1, 16_US2_AI3_to_AI2_AI3, 17_US3_AI2_to_AI3_AI2, 18_US1_AI2_to_AS1_AI2, 19_US2_AI1_to_AS2_AI1, 20_US1_AI3_to_AS1_AI3, 21_US3_AI1_to_AS3_AI1, 22_US1_AS2_to_AS1_AS2, 23_US2_AS1_to_AS2_AS1, 24_US1_AS3_to_AS1_AS3, 25_US3_AS1_to_AS3_AS1])\n",
      "\n",
      "\t\tself.timespan(numpy.linspace(0, 30, 600))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(parse_to_gillespy('network.txt', 'toy-example.mln', 'out-gillespie.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cfc458-82ac-4336-838b-96760e685871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d9b759-9d2e-4d38-81f1-810db97f4c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
