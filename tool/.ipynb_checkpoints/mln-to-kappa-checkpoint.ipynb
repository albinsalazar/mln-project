{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3a8c3091-b495-44d5-bbde-6120fd5bc9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'parser' from '/Users/ivanprigarin/Library/Mobile Documents/com~apple~CloudDocs/cloud-files/1_study/cluster/code/mln-project/tool/parser.py'>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-run this cell whenever parser.py is changed\n",
    "import importlib\n",
    "importlib.reload(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc7ab34c-2e2d-4f25-9fff-f0cc08443ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parser\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "530589bb-f798-4484-961e-5a4ecd90caf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing network configuration file network.txt\n",
      "{'actors': (['1', '2', '3'], 3),\n",
      " 'edges': ({'dir': [False, False, False, False, False],\n",
      "            'from_actor': ['1', '1', '1', '1', '2'],\n",
      "            'from_layer': ['1', '1', '2', '2', '2'],\n",
      "            'to_actor': ['2', '3', '2', '3', '3'],\n",
      "            'to_layer': ['1', '1', '2', '2', '2']},\n",
      "           [[('1', '2'), ('2', '1'), ('1', '3'), ('3', '1')],\n",
      "            [('1', '2'),\n",
      "             ('2', '1'),\n",
      "             ('1', '3'),\n",
      "             ('3', '1'),\n",
      "             ('2', '3'),\n",
      "             ('3', '2')]]),\n",
      " 'layers': (['1', '2'], 2)}\n"
     ]
    }
   ],
   "source": [
    "mln_data = parser.parse_mln('network.txt')\n",
    "pprint(mln_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4cbae9f6-02f2-48d1-9a6c-16cd6e6fa4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing MLN language file toy-example.mln\n",
      "{'initial conditions': ['1 = AI', '2 = US', '3 = US'],\n",
      " 'parameters': ['delta = 1', 'mu = 1', 'betaA = 1', 'betaU = 3', 'lamb = 1'],\n",
      " 'rules': ['AS -> US @ delta',\n",
      "           'AI -> AS @ mu',\n",
      "           'AS =1 AI -> AI =1 AI @ betaA',\n",
      "           'US =1 AI -> AI =1 AI @ betaU',\n",
      "           'US =2 AI -> AS =2 AI @ lamb',\n",
      "           'US =2 AS -> AS =2 AS @ lamb'],\n",
      " 'simOptions': ['n = 1000', 't = 30'],\n",
      " 'states': ['AS', 'AI', 'US'],\n",
      " 'views': ['AI', 'AS', 'US']}\n"
     ]
    }
   ],
   "source": [
    "language = parser.parse_language_file('toy-example.mln')\n",
    "pprint(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "95cd62bf-c6e6-407f-ab34-b0c9c8c9ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_signatures(mln_data, language):\n",
    "    signatures = ['/* Signatures */']\n",
    "    \n",
    "    states = []\n",
    "    for state in language['states']:\n",
    "        states.append(state)\n",
    "    states = '{' + ', '.join(states) + '}'\n",
    "\n",
    "    for i, actor in enumerate(mln_data['actors'][0]):\n",
    "        sites = []\n",
    "        for j, layer in enumerate(mln_data['edges'][1]):\n",
    "            for edge in layer:\n",
    "                if edge[0] == str(i+1):\n",
    "                    sites.append(f'l{j+1}v{edge[1]}')\n",
    "        sites = ', '.join(sites)\n",
    "                                 \n",
    "        kappa_signature = f'%agent: V{i+1}(state{states}, {sites})'\n",
    "        signatures.append(kappa_signature)\n",
    "        \n",
    "        \n",
    "    signatures = '\\n'.join(signatures)\n",
    "    \n",
    "    return signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1cd4aa59-11bf-46fb-9b00-fcba12b95e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Signatures */\n",
      "%agent: V1(state{AS, AI, US}, l1v2, l1v3, l2v2, l2v3)\n",
      "%agent: V2(state{AS, AI, US}, l1v1, l2v1, l2v3)\n",
      "%agent: V3(state{AS, AI, US}, l1v1, l2v1, l2v2)\n"
     ]
    }
   ],
   "source": [
    "print(parse_signatures(mln_data, language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78567761-4f7d-4f22-9496-31b8432a0161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_variables(language):\n",
    "    variables = ['/* Variables */']\n",
    "    \n",
    "    for param in language['parameters']:\n",
    "        var_name, var_value = param.split('=')\n",
    "        var = f\"%var: '{var_name.strip()}' {var_value.strip()}\"\n",
    "        variables.append(var)\n",
    "    variables = '\\n'.join(variables)\n",
    "    \n",
    "    return variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03a5c43d-932b-412b-a175-7a26149a7f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Variables */\n",
      "%var: 'delta' 1\n",
      "%var: 'mu' 1\n",
      "%var: 'betaA' 1\n",
      "%var: 'betaU' 3\n",
      "%var: 'lamb' 1\n"
     ]
    }
   ],
   "source": [
    "print(parse_variables(language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f313abcf-3b4c-4f7b-bd9e-bcc457ffad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_observables(mln_data, language):\n",
    "    observables = ['/* Observables */']\n",
    "    \n",
    "    for view in language['views']:\n",
    "        components = []\n",
    "        for i, actor in enumerate(mln_data['actors'][0]):\n",
    "            components.append(f'|V{i+1}(state{{{view}}})|')\n",
    "        obs = f\"%obs: '{view}' \" + ' + '.join(components)\n",
    "        observables.append(obs)\n",
    "    \n",
    "    observables = '\\n'.join(observables)\n",
    "    \n",
    "    return observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1ec28cf-ddb9-4d6b-a4af-a7791d183fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Observables */\n",
      "%obs: 'AI' |V1(state{AI})| + |V2(state{AI})| + |V3(state{AI})|\n",
      "%obs: 'AS' |V1(state{AS})| + |V2(state{AS})| + |V3(state{AS})|\n",
      "%obs: 'US' |V1(state{US})| + |V2(state{US})| + |V3(state{US})|\n"
     ]
    }
   ],
   "source": [
    "print(parse_observables(mln_data, language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "14f2863a-f6d1-4f53-bf40-3c4bee51b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_initial_conditions(mln_data, language):\n",
    "    n = ''\n",
    "    for line in language['simOptions']:\n",
    "        option, value = line.split('=')\n",
    "        if option.strip() == 'n':\n",
    "            n = value.strip()\n",
    "            break\n",
    "            \n",
    "    i_c = ['/* Initial conditions */',\n",
    "           f'%init: {n} (']\n",
    "    \n",
    "    initial_states = [x.split('=') for x in language['initial conditions']]\n",
    "\n",
    "    for i, actor in enumerate(mln_data['actors'][0]):\n",
    "        sites = []\n",
    "        site_labels = []\n",
    "        for j, layer in enumerate(mln_data['edges'][1]):\n",
    "            for edge in layer:\n",
    "                if edge[0] == str(i+1):\n",
    "                    # weird way to keep site labels consistent.\n",
    "                    # will need a rewrite\n",
    "                    if i+1 <= int(edge[1]):\n",
    "                        site_label = f'{j+1}{i+1}{edge[1]}'\n",
    "                    else:\n",
    "                        site_label = f'{j+1}{edge[1]}{i+1}'\n",
    "                        \n",
    "                    sites.append(f'l{j+1}v{edge[1]}[{site_label}]')\n",
    "        sites = ', '.join(sites)\n",
    "        \n",
    "        initial_state = ''\n",
    "        for state in initial_states:\n",
    "            if state[0].strip() == str(i+1):\n",
    "                initial_state = state[1].strip()\n",
    "                \n",
    "        condition = f'V{i+1}(state{{{initial_state}}}, {sites})'\n",
    "        \n",
    "        # add a comma unless it's the last entry\n",
    "        if i + 1 < int(mln_data['actors'][1]):\n",
    "            condition += ','\n",
    "        \n",
    "        i_c.append(condition)\n",
    "    \n",
    "    i_c.append(')')\n",
    "        \n",
    "    i_c = '\\n'.join(i_c)\n",
    "    \n",
    "    return i_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b17a1b54-1df4-494c-ab98-2423fc3bfdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Initial conditions */\n",
      "%init: 1000 (\n",
      "V1(state{AI}, l1v2[112], l1v3[113], l2v2[212], l2v3[213]),\n",
      "V2(state{US}, l1v1[112], l2v1[212], l2v3[223]),\n",
      "V3(state{US}, l1v1[113], l2v1[213], l2v2[223])\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(parse_initial_conditions(mln_data, language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6f7a5425-dfc1-406c-a469-ca90b233858c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rules(mln_data, language):\n",
    "    kappa_rules = ['/* Rules */']\n",
    "    \n",
    "    rules = [x.split('@') for x in language['rules']]\n",
    "    rules_organised = []\n",
    "    for ruleset in rules:\n",
    "        rules_organised.append({'rule': ruleset[0].strip(), 'rate': ruleset[1].strip()})\n",
    "\n",
    "    for ruleset in rules_organised:\n",
    "        if '=' not in ruleset['rule']:\n",
    "            # parse rules not dependant on layers\n",
    "            rule_states = [state.strip() for state in ruleset['rule'].split('->')]\n",
    "            kappa_rules.append(f\"'{rule_states[0]} to {rule_states[1]}'\")\n",
    "            for i, actor in enumerate(mln_data['actors'][0]):\n",
    "                kappa_rule = f\"V{i+1}(state{{{rule_states[0]}}}) -> V{i+1}(state{{{rule_states[1]}}}) @ '{ruleset['rate']}'\"\n",
    "                kappa_rules.append(kappa_rule)\n",
    "        else:\n",
    "            # parse intra-layer rules\n",
    "            # requires rules in both directions\n",
    "            rule_sides = [state.strip() for state in ruleset['rule'].split('->')]\n",
    "            layer = rule_sides[0][rule_sides[0].index('=')+1].strip()\n",
    "\n",
    "            states = [[x[0].strip(), x[1].strip()] for x in [rule_side.split(f'={layer}') for rule_side in rule_sides]]\n",
    "            kappa_rules.append(f\"'{layer}: {states[0][0]}-{states[0][1]} to {states[1][0]}-{states[1][1]}'\")\n",
    "            for edge in mln_data['edges'][1][int(layer)-1]:\n",
    "                v1, v2 = edge[0], edge[1]\n",
    "                kappa_rules.append(f\"// V{v1} - V{v2}\")\n",
    "                site_label = f'{layer}{v1}{v2}'\n",
    "                kappa_rule = (f'V{v1}(state{{{states[0][0]}}}, l{layer}v{v2}[{site_label}]), V{v2}(state{{{states[0][1]}}}, l{layer}v{v1}[{site_label}]) -> '\n",
    "                    f'V{v1}(state{{{states[1][0]}}}, l{layer}v{v2}[{site_label}]), V{v2}(state{{{states[1][1]}}}, l{layer}v{v1}[{site_label}]) @ '\n",
    "                    f\"'{ruleset['rate']}'\")\n",
    "\n",
    "                kappa_rules.append(kappa_rule)\n",
    "\n",
    "        kappa_rules.append('')\n",
    "\n",
    "    kappa_rules = '\\n'.join(kappa_rules)\n",
    "\n",
    "    return kappa_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4ca1327c-56a6-4ece-980b-abbaa8747e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Rules */\n",
      "'AS to US'\n",
      "V1(state{AS}) -> V1(state{US}) @ 'delta'\n",
      "V2(state{AS}) -> V2(state{US}) @ 'delta'\n",
      "V3(state{AS}) -> V3(state{US}) @ 'delta'\n",
      "\n",
      "'AI to AS'\n",
      "V1(state{AI}) -> V1(state{AS}) @ 'mu'\n",
      "V2(state{AI}) -> V2(state{AS}) @ 'mu'\n",
      "V3(state{AI}) -> V3(state{AS}) @ 'mu'\n",
      "\n",
      "'1: AS-AI to AI-AI'\n",
      "// V1 - V2\n",
      "V1(state{AS}, l1v2[112]), V2(state{AI}, l1v1[112]) -> V1(state{AI}, l1v2[112]), V2(state{AI}, l1v1[112]) @ 'betaA'\n",
      "// V2 - V1\n",
      "V2(state{AS}, l1v1[121]), V1(state{AI}, l1v2[121]) -> V2(state{AI}, l1v1[121]), V1(state{AI}, l1v2[121]) @ 'betaA'\n",
      "// V1 - V3\n",
      "V1(state{AS}, l1v3[113]), V3(state{AI}, l1v1[113]) -> V1(state{AI}, l1v3[113]), V3(state{AI}, l1v1[113]) @ 'betaA'\n",
      "// V3 - V1\n",
      "V3(state{AS}, l1v1[131]), V1(state{AI}, l1v3[131]) -> V3(state{AI}, l1v1[131]), V1(state{AI}, l1v3[131]) @ 'betaA'\n",
      "\n",
      "'1: US-AI to AI-AI'\n",
      "// V1 - V2\n",
      "V1(state{US}, l1v2[112]), V2(state{AI}, l1v1[112]) -> V1(state{AI}, l1v2[112]), V2(state{AI}, l1v1[112]) @ 'betaU'\n",
      "// V2 - V1\n",
      "V2(state{US}, l1v1[121]), V1(state{AI}, l1v2[121]) -> V2(state{AI}, l1v1[121]), V1(state{AI}, l1v2[121]) @ 'betaU'\n",
      "// V1 - V3\n",
      "V1(state{US}, l1v3[113]), V3(state{AI}, l1v1[113]) -> V1(state{AI}, l1v3[113]), V3(state{AI}, l1v1[113]) @ 'betaU'\n",
      "// V3 - V1\n",
      "V3(state{US}, l1v1[131]), V1(state{AI}, l1v3[131]) -> V3(state{AI}, l1v1[131]), V1(state{AI}, l1v3[131]) @ 'betaU'\n",
      "\n",
      "'2: US-AI to AS-AI'\n",
      "// V1 - V2\n",
      "V1(state{US}, l2v2[212]), V2(state{AI}, l2v1[212]) -> V1(state{AS}, l2v2[212]), V2(state{AI}, l2v1[212]) @ 'lamb'\n",
      "// V2 - V1\n",
      "V2(state{US}, l2v1[221]), V1(state{AI}, l2v2[221]) -> V2(state{AS}, l2v1[221]), V1(state{AI}, l2v2[221]) @ 'lamb'\n",
      "// V1 - V3\n",
      "V1(state{US}, l2v3[213]), V3(state{AI}, l2v1[213]) -> V1(state{AS}, l2v3[213]), V3(state{AI}, l2v1[213]) @ 'lamb'\n",
      "// V3 - V1\n",
      "V3(state{US}, l2v1[231]), V1(state{AI}, l2v3[231]) -> V3(state{AS}, l2v1[231]), V1(state{AI}, l2v3[231]) @ 'lamb'\n",
      "// V2 - V3\n",
      "V2(state{US}, l2v3[223]), V3(state{AI}, l2v2[223]) -> V2(state{AS}, l2v3[223]), V3(state{AI}, l2v2[223]) @ 'lamb'\n",
      "// V3 - V2\n",
      "V3(state{US}, l2v2[232]), V2(state{AI}, l2v3[232]) -> V3(state{AS}, l2v2[232]), V2(state{AI}, l2v3[232]) @ 'lamb'\n",
      "\n",
      "'2: US-AS to AS-AS'\n",
      "// V1 - V2\n",
      "V1(state{US}, l2v2[212]), V2(state{AS}, l2v1[212]) -> V1(state{AS}, l2v2[212]), V2(state{AS}, l2v1[212]) @ 'lamb'\n",
      "// V2 - V1\n",
      "V2(state{US}, l2v1[221]), V1(state{AS}, l2v2[221]) -> V2(state{AS}, l2v1[221]), V1(state{AS}, l2v2[221]) @ 'lamb'\n",
      "// V1 - V3\n",
      "V1(state{US}, l2v3[213]), V3(state{AS}, l2v1[213]) -> V1(state{AS}, l2v3[213]), V3(state{AS}, l2v1[213]) @ 'lamb'\n",
      "// V3 - V1\n",
      "V3(state{US}, l2v1[231]), V1(state{AS}, l2v3[231]) -> V3(state{AS}, l2v1[231]), V1(state{AS}, l2v3[231]) @ 'lamb'\n",
      "// V2 - V3\n",
      "V2(state{US}, l2v3[223]), V3(state{AS}, l2v2[223]) -> V2(state{AS}, l2v3[223]), V3(state{AS}, l2v2[223]) @ 'lamb'\n",
      "// V3 - V2\n",
      "V3(state{US}, l2v2[232]), V2(state{AS}, l2v3[232]) -> V3(state{AS}, l2v2[232]), V2(state{AS}, l2v3[232]) @ 'lamb'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(parse_rules(mln_data, language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7d13885a-1299-4df7-9b5d-15b68b03f119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing network configuration file network.txt\n",
      "Parsing MLN language file toy-example.mln\n",
      "Successfully exported model into Kappa: out-kappa.txt\n"
     ]
    }
   ],
   "source": [
    "parser.parse_to_kappa('network.txt', 'toy-example.mln', 'out-kappa.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f472fe-c57f-46c1-9c17-b010b49ac9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
